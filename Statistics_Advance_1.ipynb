{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Advance 1 : Theorical Questions"
      ],
      "metadata": {
        "id": "XnWuWwgUrvPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a random variable in probability theory?\n",
        "  - A random variable in probability theory is basically a way to assign numbers to the outcomes of a random experiment.\n",
        "  - It is a set of possible values from a random experiment.\n",
        "  - There are two main types of random variables :\n",
        "      - Discrete random variables, which take specific values (like 1, 2, 3, etc.).\n",
        "      - Continuous random variables, which can take any value within a range (like someone's height or the time it takes for something to happen)."
      ],
      "metadata": {
        "id": "6VWjzyuTr5El"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the types of random variables?\n",
        "  - There are two main types of random variables in probability theory :\n",
        "  - Discrete Random Variable :\n",
        "      - A discrete random variable takes on countable values. These values are usually whole numbers and come from things like rolling a die, counting the number of heads in coin tosses or the number of students in a class.\n",
        "      - Example : If we flip a coin 3 times, the number of times it lands on heads (0, 1, 2 or 3) is a discrete random variable.\n",
        "  - Continuous Random Variable :    \n",
        "      - A continuous random variable can take on any value within a certain range. These are usually things we measure rather than count, like time, temperature, weight or height.\n",
        "      - Example : The amount of time it takes someone to run a mile could be 7.2 minutes, 7.25 minutes or 7.253 minutes-basically, an infinite number of possible values in a range."
      ],
      "metadata": {
        "id": "TpiIk-cBtYEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the difference between discrete and continuous distributions?\n",
        "  - The Difference Between Discrete and Continuous Distributions :     \n",
        "  - Discrete Distributions :\n",
        "      - These deal with countable outcomes.\n",
        "      - The values jump from one number to the next without anything in between.\n",
        "      - Example : The Binomial distribution is a common discrete distribution. It could describe how many times we get heads when flipping a coin 10 times.\n",
        "  - Continuous Distributions :\n",
        "      - These handle measurable outcomes, and the values can be any number within a range, even decimals or fractions.\n",
        "      - There are infinite possibilities between any two values.\n",
        "      - Example : The Normal distribution (bell curve) is a well-known continuous distribution. It might describe the distribution of people's heights in a population."
      ],
      "metadata": {
        "id": "h3x55X2ivKcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What are probability distribution functions (PDF)?\n",
        "  - A Probability Distribution Function is a way to describe how the values of a random variable are spread out and how likely each value is.\n",
        "  - it tells us :\n",
        "      - What values a random variable can take.\n",
        "      - How likely each of those values is to happen.\n",
        "  - There are two common types :\n",
        "      - For discrete random variables (we usually talk about the Probability Mass Function (PMF)), the function gives the probability of each specific value. Example : The chance of getting a 4 when we roll a die.\n",
        "      - For continuous random variables (we use the term Probability Density Function (PDF)), the function shows how likely the variable is to fall within a certain range (not just a single number). Example : The chance that someone's height is between 160 cm and 170 cm."
      ],
      "metadata": {
        "id": "gEO9HFFywox6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "  - Both PDF and CDF are used to describe the behavior of random variables.\n",
        "  - Probability Distribution Function (PDF) :\n",
        "      - Tells us the likelihood of a specific value (for discrete variables) or the likelihood of values within a small range (for continuous variables).\n",
        "      - It shows how probabilities are spread out.\n",
        "      - Example : If we are rolling a die, the PDF might tell us that the chance of rolling a 3 is 1/6.\n",
        "  - Cumulative Distribution Function (CDF) :\n",
        "      - Tells us the total probability that a value is less than or equal to a certain number.\n",
        "      - It adds up the probabilities from the beginning up to a certain point.\n",
        "      - Example : Using the same die, the CDF for the value 3 would be :\n",
        "P(1 or 2 or 3) = 1/6 + 1/6 + 1/6 = 1/2."
      ],
      "metadata": {
        "id": "29dn66U8zmAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is a discrete uniform distribution?\n",
        "  - A discrete uniform distribution is a type of probability distribution where all outcomes are equally likely. In simple terms, if we have a set of possible values and each one has the same chance of happening, that's a discrete uniform distribution.\n",
        "  - Example : Think of rolling a fair six-sided die. The possible outcomes are : 1, 2, 3, 4, 5 and 6. Each number has the same probability of 1/6. So, this is a discrete uniform distribution.\n",
        "  - Key Features :\n",
        "      - The values are countable (discrete).\n",
        "      - Each value has an equal probability.\n",
        "      - It's often used when there's no bias toward any particular outcome."
      ],
      "metadata": {
        "id": "BqdRJr9E6Vwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What are the key properties of a Bernoulli distribution?\n",
        "  - A Bernoulli distribution models a situation where there are only two possible outcomes : usually called \"success\" and \"failure\".\n",
        "  - Think of it like flipping a coin : Heads = success, Tails = failure.\n",
        "  - Key Properties of a Bernoulli Distribution :\n",
        "      - Only Two Outcomes : The outcomes are usually coded as 1 (success) and 0 (failure).\n",
        "      - One Trial : It represents the probability of a single event happening (like flipping one coin or answering one yes/no question).\n",
        "      - Probability of Success (p) : There's a fixed probability p for success. The probability of failure is 1-p.\n",
        "      - Mean (Expected Value) : The mean of a Bernoulli distribution is p.\n",
        "      - Variance : The variance is p(1-p), which shows how much the outcomes vary."
      ],
      "metadata": {
        "id": "uX3sWCjl7l4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the binomial distribution and how is it used in probability?\n",
        "  - The binomial distribution is used when we want to know the probability of getting a certain number of successes in a fixed number of trials, where each trial has only two possible outcomes (like success or failure).\n",
        "  - Key Features :\n",
        "      - There is a fixed number of trials (like 10 coin flips).\n",
        "      - Each trial has only two outcomes (success/failure, yes/no, correct/wrong).\n",
        "      - The probability of success is the same in every trial.\n",
        "      - The trials are independent (the result of one does not affect the others).\n",
        "  - How it is Used in Probability :    \n",
        "      - The binomial distribution is used when we want to predict or understand the likelihood of a certain number of successes over several attempts.\n",
        "      - Example : What's the chance of guessing 3 out of 5 multiple-choice answers correctly?"
      ],
      "metadata": {
        "id": "Yqp_jlE39LyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the Poisson distribution and where is it applied?\n",
        "  - The Poisson distribution is a probability distribution used to model the number of times an event happens in a fixed period of time or space, when the events happen randomly and independently of each other.\n",
        "  - It helps answer questions like :\n",
        "      - \"How many emails will I get in an hour?\"\n",
        "      - \"How many accidents will happen at this intersection in a day?\"\n",
        "  - Key Features :\n",
        "      - It counts how often an event happens in a fixed interval (of time, area, distance, etc.).\n",
        "      - The events must happen independently (one doesn't affect another).\n",
        "      - The average rate of occurrence (called \"lambda\") stays the same over time.\n",
        "  - Where it is applied :\n",
        "      - The Poisson distribution is often used when we are tracking rare or random events over time or space. Some common uses include :\n",
        "      - Traffic Flow : Number of cars passing through a toll booth per minute.\n",
        "      - Customer Service : Number of people arriving at a store or calling a help desk in an hour.\n",
        "      - Healthcare : Number of patients arriving at an emergency room in a day."
      ],
      "metadata": {
        "id": "EhN62CYM_ctY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is a continuous uniform distribution?\n",
        "  - A continuous uniform distribution is a type of probability distribution where all values within a certain range are equally likely to occur.\n",
        "  - Example :\n",
        "      - Imagine we are picking a random time between 2 PM and 3 PM.\n",
        "      - Any time between 2:00 and 3:00 - like 2:05, 2:30 or 2:59 - is equally likely.\n",
        "      - That's a continuous uniform distribution, because the time can be any value (not just whole minutes) and all values are equally likely.\n",
        "  - Key Features :\n",
        "      - The values are continuous (we can have decimals or fractions).\n",
        "      - The probability is evenly spread across the entire range.\n",
        "      - The distribution is defined over a minimum value (a) and a maximum value (b).\n",
        "      - The probability density is constant across the range."
      ],
      "metadata": {
        "id": "LGzRSP7uCF_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are the characteristics of a normal distribution?\n",
        "  - A normal distribution is one of the most important and commonly used probability distributions in statistics. It's often called the bell curve because of its smooth, symmetric, bell-shaped appearance.\n",
        "  -  Key Characteristics of a Normal Distribution :\n",
        "      - Symmetrical Shape : The curve is perfectly symmetrical around the mean (center). This means the left and right sides are mirror images.\n",
        "      - Mean = Median = Mode : The highest point of the curve is the mean and it's also the median and mode.\n",
        "      - Bell-Shaped Curve : Most of the data is clustered around the center (mean) and the probabilities taper off evenly on both sides.\n",
        "      - Defined by Two Parameters : Mean - tells us the center of the distribution. Standard Deviation - tells us how spread out the data is.\n",
        "      - Empirical Rule (68-95-99.7 Rule) : About 68% of values lie within 1 standard deviation of the mean. About 95% within 2 standard deviations. About 99.7% within 3 standard deviations\n",
        "      - Total Area = 1 : The total area under the curve is 1, representing 100% of the data."
      ],
      "metadata": {
        "id": "SFKFxTCdKpET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the standard normal distribution and why is it important?\n",
        "  - The standard normal distribution is a special type of normal distribution that has : A mean (average) of 0 and A standard deviation of 1.\n",
        "  - It's still the familiar bell-shaped curve, but it's been \"standardized\" so we can easily compare different sets of data.\n",
        "  - Why it is important :     \n",
        "      - It simplifies calculations : When we convert data to this form (called a z-score), we can use standard tables or software to find probabilities quickly.\n",
        "      - It allows comparison across different situations : For example, if two students take different exams, we can convert their scores to the standard normal form and compare their performance fairly.\n",
        "      - It's used in many statistical methods : Things like hypothesis testing, confidence intervals and control charts rely on the standard normal distribution."
      ],
      "metadata": {
        "id": "tKruwGxBMWk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "  - The Central Limit Theorem says that - When we take many random samples from any population (no matter the shape), the average (mean) of those samples will follow a normal distribution - as long as the sample size is large enough.\n",
        "  - Key Points :\n",
        "      - It works for any population shape (even if it's not normally distributed).\n",
        "      - It applies when the sample size is large (usually 30 or more is good enough).\n",
        "      - The sampling distribution of the sample mean becomes normal.\n",
        "      - The mean of this distribution is the same as the population mean.\n",
        "      - The spread (standard error) gets smaller as the sample size increases.\n",
        "  - Why it is important :\n",
        "      - It makes statistical analysis possible - Because of the CLT, we can use normal distribution methods (like z-scores, confidence intervals and hypothesis tests) even if the original data isn't normal.\n",
        "      - It helps us make predictions about populations - By taking just a sample, we can estimate things about the entire group with confidence.\n",
        "      - It's the foundation of many statistical tools - Most inferential statistics (tools we use to draw conclusions from data) rely on the CLT."
      ],
      "metadata": {
        "id": "-18zGtWoOiuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "  - The Central Limit Theorem (CLT) explains why the normal distribution is so important and common in statistics.\n",
        "  -It states that if we take many random samples from any population - no matter what shape it has - and calculate their averages, the distribution of those sample means will start to resemble a normal distribution as the sample size increases.\n",
        "  - In simple terms, even if our original data is not normally distributed, the distribution of the sample means will be approximately normal, thanks to the CLT.\n",
        "  - The CLT acts as a bridge between all types of data and the normal distribution, which is why the normal distribution appears so often in real-world statistics - even when the original data is not normal."
      ],
      "metadata": {
        "id": "ZG79EboxQ7Ij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the application of Z statistics in hypothesis testing?\n",
        "  - Z-statistics are used in hypothesis testing to determine whether a sample mean is significantly different from a known population mean. When the population standard deviation is known and the sample size is large, the Z-statistic helps decide whether to accept or reject the null hypothesis by comparing the calculated Z-value to a critical value from the Z-distribution.\n",
        "  - There are two main applications :\n",
        "      - One-sample Z-test : Used to compare the mean of a single sample to a known population mean.\n",
        "      - Two-sample Z-test : Used to compare the means of two independent samples.\n",
        "  - In both cases, the Z-statistic helps determine whether to accept or reject the null hypothesis by comparing the calculated Z-value to a critical value from the standard normal distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "MP-zEjsCUDyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How do you calculate a Z-score, and what does it represent?\n",
        "  - Z-score is calculated using the formula : $$\n",
        "Z = \\frac{X - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "  - Where :\n",
        "      - X = the value we are analyzing\n",
        "      - μ = the population mean\n",
        "      - σ = the population standard deviation\n",
        "  - What it Represents :\n",
        "      - A Z-score tells us how many standard deviations a value is from the mean.\n",
        "      - A Z-score of 0 means the value is exactly at the mean.\n",
        "      - A positive Z-score means the value is above the mean.\n",
        "      - A negative Z-score means the value is below the mean.\n",
        "  - Example : If a student's test score has a Z-score of +2, it means their score is 2 standard deviations above the average."
      ],
      "metadata": {
        "id": "J7wn_OUFbK_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are point estimates and interval estimates in statistics?\n",
        "  - A point estimate is a single value used to estimate an unknown population parameter. Example : Using the sample mean to estimate the population mean.\n",
        "  - An interval estimate gives a range of values (an interval) that is likely to contain the population parameter. Example : A confidence interval of 95% for the population mean is an interval estimate.\n",
        "  - In Simple Terms :\n",
        "      - Point estimate = One best guess.\n",
        "      - Interval estimate = A range of guesses with a level of confidence (like 95%)."
      ],
      "metadata": {
        "id": "8hPBedd7d48o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the significance of confidence intervals in statistical analysis?\n",
        "  - Confidence intervals provide a range of values that likely contain the true population parameter, based on sample data. They help show how precise or reliable an estimate is. For example, a 95% confidence interval means we are 95% confident that the true value lies within that range.\n",
        "  - Why It's Important :\n",
        "      - It gives more information than a single point estimate.\n",
        "      - It helps in decision-making by showing the uncertainty around an estimate.\n",
        "      - Wider intervals mean less precision; narrower intervals mean more precision."
      ],
      "metadata": {
        "id": "CCIGkWQAfAGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is the relationship between a Z-score and a confidence interval?\n",
        "  - A Z-score is used to calculate a confidence interval when the population standard deviation is known and the data is normally distributed.\n",
        "  - Each confidence level corresponds to a specific Z-score :\n",
        "      - For 90% confidence, Z ≈ 1.645\n",
        "      - For 95% confidence, Z ≈ 1.96\n",
        "      - For 99% confidence, Z ≈ 2.576\n",
        "  - The Z-score sets the \"margin\" for how wide the confidence interval should be. A higher confidence level uses a larger Z-score, which creates a wider interval.\n",
        "  - The confidence interval is calculated as : $$\n",
        "\\text{CI} = \\bar{X} \\pm Z \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
        "$$\n",
        "\n",
        "  - Where :\n",
        "      - X̄ = sample mean\n",
        "      - σ = population standard deviation\n",
        "      - n = sample size."
      ],
      "metadata": {
        "id": "o6s3w9hLhHyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How are Z-scores used to compare different distributions?\n",
        "  - Z-scores standardize values from different distributions by converting them into a common scale - the standard normal distribution (mean = 0, standard deviation = 1). This allows us to compare values from different datasets, even if they have different means and standard deviations.\n",
        "  - Z-score tells us how many standard deviations a value is from its mean.\n",
        "  - By converting values into Z-scores, we can directly compare them - even if they come from different units or distributions.\n",
        "  - Example :    \n",
        "      - A student scores 80 in Math (mean = 70, SD = 5)\n",
        "      - Another scores 85 in Science (mean = 75, SD = 10)\n",
        "      - Calculate the Z-score for each student. (Zm = 2 and Zs = 1)\n",
        "      - The Z-score for the Math student is 2, which means their score is 2 standard deviations above the mean of their group.\n",
        "      - The Z-score for the Science student is 1, which means their score is 1 standard deviation above the mean of their group.\n",
        "      - Even though the Math student's score (80) is higher than the Science student's score (85), the Math student performed better relative to their own group since their score is 2 standard deviations above the mean, compared to the Science student's score which is only 1 standard deviation above the mean."
      ],
      "metadata": {
        "id": "RY7YX4UIj4aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What are the assumptions for applying the Central Limit Theorem?\n",
        "  - To apply the Central Limit Theorem (CLT) correctly, the following assumptions should be met:\n",
        "      - Random Sampling : The data should be collected using a random and independent sampling process.\n",
        "      - Sample Size : The sample size should be large enough (typically n ≥ 30). If the population is not normal, a larger sample is needed. If the population is normal, smaller samples may still work.\n",
        "      - Independence : Each observation must be independent of the others. If sampling without replacement, the sample size should be less than 10% of the population.\n",
        "      - Finite Variance : The population should have a finite variance (no extreme outliers or infinite spread)."
      ],
      "metadata": {
        "id": "FrsljbI0nYUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the concept of expected value in a probability distribution?\n",
        "  - The expected value is the average outcome we would expect if we repeated a random experiment many times. It represents the long-term average or mean of a probability distribution.\n",
        "  - For Discrete Random Variables : E(X) = ∑ [x * P(x)]\n",
        "\n",
        "  - Where :\n",
        "      - x = each possible outcome\n",
        "      - P(x) = probability of that outcome\n",
        "  - The expected value tells us what we can expect on average over time.\n",
        "  - It might not be a value that actually occurs, but it gives us a good idea of what to predict in the long run."
      ],
      "metadata": {
        "id": "8RBJFHprpMzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "  - A probability distribution describes all the possible values a random variable can take, along with their associated probabilities. The expected outcome (or expected value) is the average value we would expect if the experiment were repeated many times and it is calculated using the probability distribution.\n",
        "  - The probability distribution weights each outcome by how likely it is to occur.\n",
        "  - The expected value is found by multiplying each value by its probability and adding them all together.\n",
        "  - The expected value is like the \"center\" or average of a probability distribution.\n",
        "  - It's how the probabilities and outcomes work together to show what we would expect in the long run."
      ],
      "metadata": {
        "id": "7KDZQ4xTreuT"
      }
    }
  ]
}